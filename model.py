# -*- coding: utf-8 -*-
"""credit risk.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17Zn1I4sdq0r1ah2t-m5tur3x6UUnr_UX
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df=pd.read_csv('Credit Risk Prediction.csv')

df.head()

df.columns

df.shape

df.isnull().sum()

df['Credit_Limit'].value_counts()

df.info()

df.describe()

# for i in df.columns:
#   sns.histplot(data=df,x=i,kde=True)
#   plt.show()

# for i in df.columns:
#   sns.boxplot(data=df,x=i)
#   plt.show()

df.columns

d=df.corr()
print(d)

fig_dims = (20, 20)
fig, ax = plt.subplots(figsize=fig_dims)
sns.heatmap(d,annot=True)

print(d[['Will_Default_Next_Month']].sort_values(by='Will_Default_Next_Month', ascending=False))

df.columns

"""  df['Credit_Limit','age_years','Education_level','bilAmt_sep'all bit amouts]"""

sns.lineplot(data=df,x='Credit_Limit',y='Will_Default_Next_Month')
plt.show()

sns.lineplot(data=df,x='Age_Years',y='Will_Default_Next_Month')
plt.show()

sns.boxplot(data=df,x='Education_Level')
plt.show()

"""only 3 dont remove"""

df.columns

# for i in ['BillAmt_Sep', 'BillAmt_Aug',
#        'BillAmt_Jul', 'BillAmt_Jun', 'BillAmt_May', 'BillAmt_Apr','PaidAmt_Sep', 'PaidAmt_Aug', 'PaidAmt_Jul', 'PaidAmt_Jun',
#        'PaidAmt_May', 'PaidAmt_Apr']:
#        sns.lineplot(data=df,x=i,y='Will_Default_Next_Month')
#        sns.boxplot(data=df,x=i)
#        plt.show()

# for i in['BillAmt_Sep', 'BillAmt_Aug',
#        'BillAmt_Jul', 'BillAmt_Jun', 'BillAmt_May', 'BillAmt_Apr']:
#        sns.boxplot(data=df,x=i)
#        plt.show()

def wisker(col):
  q1,q3=np.percentile(col,[25,75])
  iqr=q3-q1
  lw=q1-(1.5*iqr)
  uw=q3+(1.5*iqr)
  return lw,uw

for i in ['Credit_Limit']:
  lw,uw=wisker(df[i])
  df[i]=np.where(df[i]>uw,uw,df[i])
  df[i]=np.where(df[i]<lw,lw,df[i])

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

df.columns

x = df[['Credit_Limit', 'Gender_Code', 'Education_Level',
       'Marital_Status', 'Age_Years', 'Repay_Sep', 'Repay_Aug', 'Repay_Jul',
       'Repay_Jun', 'Repay_May', 'Repay_Apr', 'BillAmt_Sep', 'BillAmt_Aug',
       'BillAmt_Jul', 'BillAmt_Jun', 'BillAmt_May', 'BillAmt_Apr',
       'PaidAmt_Sep', 'PaidAmt_Aug', 'PaidAmt_Jul', 'PaidAmt_Jun',
       'PaidAmt_May', 'PaidAmt_Apr']]
y = df['Will_Default_Next_Month']
x_train,x_test,y_train,y_test=train_test_split(x,y,stratify=y,test_size=0.2,random_state=42)

from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
x_train=scaler.fit_transform(x_train)
x_test=scaler.transform(x_test)

from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(x_train, y_train)
y_pred = model.predict(x_test)
print(accuracy_score(y_test, y_pred))

"""Accuracy=80.7"""

from sklearn.tree import DecisionTreeClassifier
model = DecisionTreeClassifier(random_state=42)
scaler=StandardScaler()
x_train=scaler.fit_transform(x_train)
x_test=scaler.transform(x_test)
model.fit(x_train, y_train)
y_dc = model.predict(x_test)

"""Here are the Precision, Recall, and F1-score for the logisticRegression, along with its confusion matrix."""

from sklearn.metrics import classification_report, confusion_matrix

print("Classification Report for DecisionTreeClassifier:")
print(classification_report(y_test, y_dc))

print("Confusion Matrix for DecisionTreeClassifier:")
print(confusion_matrix(y_test, y_dc))

from sklearn.metrics import accuracy_score
print("Accuracy score for DecisionTreeClassifier:")
print(accuracy_score(y_test, y_dc))

from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(random_state=42)
model.fit(x_train, y_train)
y_rf = model.predict(x_test)

"""Here are the Precision, Recall, and F1-score for the RandomForestClassifier, along with its confusion matrix."""

from sklearn.metrics import classification_report, confusion_matrix,accuracy_score

print("Classification Report for RandomForestClassifier:")
print(classification_report(y_test, y_rf))

print("Confusion Matrix for RandomForestClassifier:")
print(confusion_matrix(y_test, y_rf))

print("Accuracy score for RandomForestClassifier:")
print(accuracy_score(y_test, y_rf))

from sklearn.svm import SVC
model = SVC(random_state=42)
model.fit(x_train, y_train)
y_svm = model.predict(x_test)
from sklearn.metrics import accuracy_score
svm_accuracy_score = accuracy_score(y_test, y_pred)
print(svm_accuracy_score)

"""Here are the Precision, Recall, and F1-score for the svm, along with its confusion matrix."""

from sklearn.metrics import classification_report, confusion_matrix,accuracy_score

print("Classification Report for SVM classifier:")
print(classification_report(y_test, y_svm))

print("Confusion Matrix for SVM classifier:")
print(confusion_matrix(y_test, y_svm))

print("Accuracy score for SVM classifier:")
print(accuracy_score(y_test, y_svm))

from sklearn.neighbors import KNeighborsClassifier
model = KNeighborsClassifier()
model.fit(x_train, y_train)
y_knn = model.predict(x_test)
from sklearn.metrics import accuracy_score
print(accuracy_score(y_test, y_pred))

"""Here are the Precision, Recall, and F1-score for the knn clasifier, along with its confusion matrix."""

from sklearn.metrics import classification_report, confusion_matrix,accuracy_score

print("Classification Report for KNeighborsClassifier:")
print(classification_report(y_test, y_knn))

print("Confusion Matrix for KNeighborsClassifier:")
print(confusion_matrix(y_test, y_knn))

print("Accuracy score for KNeighborsClassifier:")
print(accuracy_score(y_test, y_knn))

from sklearn.ensemble import GradientBoostingClassifier
model_gb = GradientBoostingClassifier(random_state=42)
model_gb.fit(x_train, y_train)
y_pred_gb = model_gb.predict(x_test)
print(accuracy_score(y_test, y_pred_gb))

"""Here are the Precision, Recall, and F1-score for the GradientBoostingClassifier, along with its confusion matrix."""

from sklearn.metrics import classification_report, confusion_matrix,accuracy_score

print("Classification Report for GradientBoostingClassifier:")
print(classification_report(y_test, y_pred_gb))

print("Confusion Matrix for GradientBoostingClassifier:")
print(confusion_matrix(y_test, y_pred_gb))

print("Accuracy score for GradientBoostingClassifier:")
print(accuracy_score(y_test, y_pred_gb))

import xgboost as xgb
model_xgb = xgb.XGBClassifier(random_state=42)
model_xgb.fit(x_train, y_train)
y_pred_xgb = model_xgb.predict(x_test)
print(accuracy_score(y_test, y_pred_xgb))

"""Here are the Precision, Recall, and F1-score for the XGBClassifier, along with its confusion matrix."""

from sklearn.metrics import classification_report, confusion_matrix,accuracy_score

print("Classification Report for XGBClassifier:")
print(classification_report(y_test, y_pred_xgb))

print("Confusion Matrix for XGBClassifier:")
print(confusion_matrix(y_test, y_pred_xgb))

print("Accuracy score for XGBClassifier:")
print(accuracy_score(y_test, y_pred_xgb))

"""# Task
Retrieve the accuracy, precision, recall, and F1-score for each of the following models: Logistic Regression, Decision Tree, Random Forest, SVM, K-Nearest Neighbors, Gradient Boosting, and XGBoost. Consolidate these metrics into a pandas DataFrame, displaying each model's performance on a separate row, with columns for Accuracy, Precision (weighted average), Recall (weighted average), and F1-Score (weighted average). Finally, print the DataFrame and add a markdown cell summarizing the findings to identify the best-performing model for the classification task.

## Collect Model Metrics

### Subtask:
Extract accuracy, precision, recall, and F1-score for each trained model.

**Reasoning**:
The subtask requests to calculate the accuracy, precision, recall, and F1-score for each trained model. I will start by creating a dictionary to store these metrics for all models. Then I will calculate the metrics for the Logistic Regression model and store them in the dictionary.
"""

from sklearn.metrics import classification_report, accuracy_score

metrics = {}

# Logistic Regression Metrics
logistic_regression_accuracy = accuracy_score(y_test, y_pred)
logistic_regression_report = classification_report(y_test, y_pred, output_dict=True)

metrics['Logistic_Regression'] = {
    'accuracy': logistic_regression_accuracy,
    'precision': logistic_regression_report['weighted avg']['precision'],
    'recall': logistic_regression_report['weighted avg']['recall'],
    'f1_score': logistic_regression_report['weighted avg']['f1-score']
}

"""**Reasoning**:
Following the instructions, the next step is to calculate the accuracy and classification report for the SVM model and store these metrics in the 'metrics' dictionary.


"""

svm_accuracy = accuracy_score(y_test, y_svm)
svm_report = classification_report(y_test, y_svm, output_dict=True)

metrics['SVM'] = {
    'accuracy': svm_accuracy,
    'precision': svm_report['weighted avg']['precision'],
    'recall': svm_report['weighted avg']['recall'],
    'f1_score': svm_report['weighted avg']['f1-score']
}

"""**Reasoning**:
Continuing the task, I will now calculate the accuracy and classification report for the K-Nearest Neighbors (KNN) model and store these metrics in the 'metrics' dictionary.


"""

knn_accuracy = accuracy_score(y_test, y_knn)
knn_report = classification_report(y_test, y_knn, output_dict=True)

metrics['K_Nearest_Neighbors'] = {
    'accuracy': knn_accuracy,
    'precision': knn_report['weighted avg']['precision'],
    'recall': knn_report['weighted avg']['recall'],
    'f1_score': knn_report['weighted avg']['f1-score']
}

"""**Reasoning**:
Now I will extract the accuracy, precision, recall, and F1-score for the Decision Tree model and store these metrics in the 'metrics' dictionary, following the task instructions.


"""

dt_accuracy = accuracy_score(y_test, y_dc)
dt_report = classification_report(y_test, y_dc, output_dict=True)

metrics['Decision_Tree'] = {
    'accuracy': dt_accuracy,
    'precision': dt_report['weighted avg']['precision'],
    'recall': dt_report['weighted avg']['recall'],
    'f1_score': dt_report['weighted avg']['f1-score']
}

"""**Reasoning**:
Next, I will calculate the accuracy and classification report for the Random Forest model and store these metrics in the 'metrics' dictionary.


"""

rf_accuracy = accuracy_score(y_test, y_rf)
rf_report = classification_report(y_test, y_rf, output_dict=True)

metrics['Random_Forest'] = {
    'accuracy': rf_accuracy,
    'precision': rf_report['weighted avg']['precision'],
    'recall': rf_report['weighted avg']['recall'],
    'f1_score': rf_report['weighted avg']['f1-score']
}

"""**Reasoning**:
Continuing to follow the instructions, I will now calculate the accuracy and classification report for the Gradient Boosting model and store these metrics in the 'metrics' dictionary.


"""

gb_accuracy = accuracy_score(y_test, y_pred_gb)
gb_report = classification_report(y_test, y_pred_gb, output_dict=True)

metrics['Gradient_Boosting'] = {
    'accuracy': gb_accuracy,
    'precision': gb_report['weighted avg']['precision'],
    'recall': gb_report['weighted avg']['recall'],
    'f1_score': gb_report['weighted avg']['f1-score']
}

"""**Reasoning**:
Following the instructions, I will now calculate the accuracy and classification report for the XGBoost model and store these metrics in the 'metrics' dictionary.


"""

xgb_accuracy = accuracy_score(y_test, y_pred_xgb)
xgb_report = classification_report(y_test, y_pred_xgb, output_dict=True)

metrics['XGBoost'] = {
    'accuracy': xgb_accuracy,
    'precision': xgb_report['weighted avg']['precision'],
    'recall': xgb_report['weighted avg']['recall'],
    'f1_score': xgb_report['weighted avg']['f1-score']
}

"""**Reasoning**:
All individual model metrics have been collected and stored in the `metrics` dictionary. The next step is to consolidate these metrics into a pandas DataFrame as requested by the task.


"""

import pandas as pd

metrics_df = pd.DataFrame.from_dict(metrics, orient='index')
metrics_df.index.name = 'Model'
print(metrics_df)

"""### Summary of Model Performance

Based on the evaluation metrics presented in the `metrics_df` DataFrame, here's a summary to identify the best-performing model:

```
                     accuracy  precision    recall  f1_score
Model                                                       
Logistic_Regression  0.716167   0.725969  0.716167  0.720759
SVM                  0.816167   0.797776  0.816167  0.792174
K_Nearest_Neighbors  0.792667   0.770422  0.792667  0.775416
Decision_Tree        0.716167   0.725969  0.716167  0.720759
Random_Forest        0.815167   0.796565  0.815167  0.795250
Gradient_Boosting    0.818333   0.800658  0.818333  0.796889
XGBoost              0.810000   0.790060  0.810000  0.790542
```

Comparing the models:

*   **Accuracy**: Gradient Boosting has the highest accuracy at approximately 81.83%.
*   **Precision (weighted average)**: Gradient Boosting also has the highest precision at approximately 80.07%.
*   **Recall (weighted average)**: Gradient Boosting has the highest recall at approximately 81.83%.
*   **F1-Score (weighted average)**: Gradient Boosting has the highest F1-score at approximately 79.69%.

While SVM and Random Forest also show strong performance, **Gradient Boosting Classifier** appears to be the best-performing model for this classification task across all key metrics (Accuracy, Precision, Recall, and F1-Score).

## Summary:

### Q&A
The best-performing model for this classification task is the Gradient Boosting Classifier.

### Data Analysis Key Findings
*   Performance metrics (accuracy, weighted average precision, recall, and F1-score) were successfully retrieved for seven machine learning models: Logistic Regression, SVM, K-Nearest Neighbors, Decision Tree, Random Forest, Gradient Boosting, and XGBoost.
*   **Gradient Boosting** demonstrated the highest performance across all evaluated metrics:
    *   Accuracy: approximately 0.8183
    *   Precision (weighted average): approximately 0.8007
    *   Recall (weighted average): approximately 0.8183
    *   F1-Score (weighted average): approximately 0.7969
*   **SVM** and **Random Forest** also exhibited strong performance, with SVM achieving an accuracy of 0.8162 and Random Forest an accuracy of 0.8152, making them competitive alternatives.
*   **Logistic Regression** and **Decision Tree** showed the lowest performance among the evaluated models, both recording an accuracy of 0.7162.

### Insights or Next Steps
*   Further hyperparameter tuning or advanced ensemble techniques could be applied to the Gradient Boosting model to potentially enhance its already superior performance.
*   Analyze the feature importance derived from the Gradient Boosting model to understand which variables contribute most significantly to the classification, offering insights into the underlying data patterns.
"""
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import GradientBoostingClassifier
import joblib

# Build pipeline
pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("gb", GradientBoostingClassifier(random_state=42))
])

# Train again on full dataset
pipeline.fit(x_train, y_train)

# Save pipeline
joblib.dump(pipeline, "model.pkl")

print("Pipeline saved successfully as model.pkl")
